{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.8.3)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import heapq\n",
    "import pygame\n",
    "import random\n",
    "from env import *\n",
    "from Queue import *\n",
    "from collections import defaultdict\n",
    "from abc import ABCMeta, abstractmethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INF = float('inf')\n",
    "DELAY = 0.01\n",
    "DISTANCE = 1\n",
    "\n",
    "class Search(metaclass=ABCMeta):\n",
    "    \"\"\"\n",
    "    class for search algorithms\n",
    "    \"\"\"\n",
    "    @abstractmethod\n",
    "    def solver(self):\n",
    "        \"\"\"\n",
    "        Solver to find shortest path between start and target node\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def initialize(self):\n",
    "        \"\"\"\n",
    "        Create information required for solver\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def output(self):\n",
    "        # get cells first in case path to be drawn directly\n",
    "        cells = self.board.draw_board()   \n",
    "\n",
    "        # derive shortest path starting from target node and reverse it\n",
    "        node = self.target_node\n",
    "        while node.parent is not None:\n",
    "            self.board.path.append(node.state)\n",
    "            node = node.parent\n",
    "        self.board.path.reverse()\n",
    "\n",
    "        # draw shortest path step by step\n",
    "        colour = self.board.colours[\"p_yellow\"]                     \n",
    "        for i, j in self.board.path:\n",
    "            time.sleep(1.5*DELAY)\n",
    "            rect = cells[i][j]\n",
    "            pygame.draw.rect(self.board.screen, colour, rect)\n",
    "            pygame.display.flip()\n",
    "\n",
    "class Dijkstra(Search):\n",
    "    \"\"\"\n",
    "    Dijkstra Algorithm\n",
    "    \"\"\"\n",
    "    def __init__(self, board:Board):\n",
    "        self.board = board\n",
    "        self.find = False\n",
    "\n",
    "    def initialize(self):\n",
    "        \"\"\"\n",
    "        Create following information for solver:\n",
    "        1. adjacent list\n",
    "        2. node_dict: key is coordinate of node; value is node\n",
    "        3. distance dict to store distance between nodes and start_node\n",
    "        \"\"\"\n",
    "        self.node_dict = {}\n",
    "        self.distance = {}\n",
    "\n",
    "        # create nodes\n",
    "        for i in range(self.board.v_cells):\n",
    "            for j in range(self.board.h_cells):\n",
    "                # if (i,j) is wall, do not create Node\n",
    "                if (i,j) in self.board.wall:\n",
    "                    continue\n",
    "\n",
    "                pos = (i,j)\n",
    "                node = Node(pos, None, None)\n",
    "                if pos == self.board.start:\n",
    "                    self.start_node = node\n",
    "                elif pos == self.board.target:\n",
    "                    self.target_node = node\n",
    "\n",
    "                self.node_dict[pos] = node\n",
    "                self.distance[node] = INF\n",
    "\n",
    "        self.distance[self.start_node] = 0\n",
    "\n",
    "        # add neighbor_nodes to adjacent list with action and distance\n",
    "        self.adj_list = defaultdict(dict)\n",
    "        for _, node in self.node_dict.items():\n",
    "            # get possible neighbor positions of node\n",
    "            neighbors = self.board.neighbors(node.state)\n",
    "            for action, (row, col) in neighbors:\n",
    "                # get neighbor_node from node_dict\n",
    "                neighbor_node = self.node_dict[(row, col)]\n",
    "                # update adj_list\n",
    "                self.adj_list[node][neighbor_node] = [action, DISTANCE]\n",
    "\n",
    "    def relax(self, node:Node, neighbor: Node):\n",
    "        \"\"\"\n",
    "        Function to update distance dict for each node, and push node into heap by distance\n",
    "        \"\"\"\n",
    "        if self.distance[neighbor] > self.distance[node] + self.adj_list[node][neighbor][1]:\n",
    "\n",
    "            # update distance\n",
    "            self.distance[neighbor] = self.distance[node] + self.adj_list[node][neighbor][1]\n",
    "\n",
    "            # update parent and action take\n",
    "            neighbor.parent = node\n",
    "            neighbor.action = self.adj_list[node][neighbor][0]\n",
    "            \n",
    "            # push neighbor into heap\n",
    "            self.entry_count += 1\n",
    "            heapq.heappush(self.heap, (self.distance[neighbor], self.entry_count, neighbor))\n",
    "\n",
    "    def solver(self):\n",
    "        \"\"\"\n",
    "        Dijkstra algorithm\n",
    "        \"\"\"\n",
    "        # When pusing node into heap and there exists equal distance values, \n",
    "        # then heap will arrange those nodes in order of entry time.\n",
    "        self.heap = []\n",
    "        self.entry_count = 1\n",
    "        heapq.heappush(self.heap, (self.distance[self.start_node], self.entry_count, self.start_node))\n",
    "\n",
    "        while self.heap and self.find == False:\n",
    "            time.sleep(DELAY)\n",
    "            # Extract_Min\n",
    "            (_, _, node) = heapq.heappop(self.heap)\n",
    "            \n",
    "            # If find target node, set self.find == True\n",
    "            if node.state == self.target_node.state:\n",
    "                self.find = True\n",
    "\n",
    "            # Mark node as visited\n",
    "            self.board.visited.add(node)\n",
    "            self.board.draw_board(return_cells=False)\n",
    "            # if there is no outgoing edge, continue while loop\n",
    "            if not self.adj_list[node]:\n",
    "                continue\n",
    "\n",
    "            # if there exists outgoing edges, iteration through all edges\n",
    "            for neighbor in self.adj_list[node]:\n",
    "                if neighbor not in self.board.visited:\n",
    "                    self.relax(node, neighbor)\n",
    "            pygame.display.flip()\n",
    "\n",
    "class A_search(Search):\n",
    "    \"\"\"\n",
    "    A* Search algorithm\n",
    "    \"\"\"\n",
    "    def __init__(self, board:Board):\n",
    "        self.board = board\n",
    "        self.find = False\n",
    "\n",
    "    def initialize(self):\n",
    "        \"\"\"\n",
    "        Create following information for solver:\n",
    "        1. adjacent list\n",
    "        2. node_dict: key is coordinate of node; value is node\n",
    "        3. g_scores dictionary\n",
    "        4. h_scores dictionary\n",
    "        \"\"\"\n",
    "        self.node_dict = {}\n",
    "        self.g_scores = {}\n",
    "        self.h_scores = {}\n",
    "\n",
    "        for i in range(self.board.v_cells):\n",
    "            for j in range(self.board.h_cells):\n",
    "                if (i,j) in self.board.wall:\n",
    "                    continue\n",
    "\n",
    "                pos = (i,j)\n",
    "                node = Node(pos, None, None)\n",
    "                if pos == self.board.start:\n",
    "                    self.start_node = node\n",
    "                elif pos == self.board.target:\n",
    "                    self.target_node = node\n",
    "                \n",
    "                self.node_dict[pos] = node\n",
    "                self.g_scores[node] = INF\n",
    "                self.h_scores[node] = 0\n",
    "\n",
    "        self.g_scores[self.start_node] = 0\n",
    "\n",
    "        self.adj_list = defaultdict(dict)\n",
    "        for _, node in self.node_dict.items():\n",
    "            neighbors = self.board.neighbors(node.state)\n",
    "            for action, (row, col) in neighbors:\n",
    "                neighbor_node = self.node_dict[(row, col)]\n",
    "                self.adj_list[node][neighbor_node] = [action, DISTANCE]\n",
    "\n",
    "    def relax(self, node:Node, neighbor: Node):\n",
    "        \"\"\"\n",
    "        Function to update g_scores dict for each node, and push node into heap by g_scores+h_scores\n",
    "\n",
    "        node: selected visited node --> Node\n",
    "        neighbor: neighboring nodes haven't been visited --> Node\n",
    "        \"\"\"\n",
    "        if self.g_scores[neighbor] > self.g_scores[node] + self.adj_list[node][neighbor][1]:\n",
    "\n",
    "            # update distance\n",
    "            self.g_scores[neighbor] = self.g_scores[node] + self.adj_list[node][neighbor][1]\n",
    "\n",
    "            # update parent and action take\n",
    "            neighbor.parent = node\n",
    "            neighbor.action = self.adj_list[node][neighbor][0]\n",
    "\n",
    "            # push neighbor into heap\n",
    "            self.entry_count += 1\n",
    "            self.h_scores[neighbor] = A_search.manhattan(neighbor, self.target_node)\n",
    "            heapq.heappush(self.heap, (self.g_scores[neighbor]+self.h_scores[neighbor], self.entry_count,neighbor))\n",
    "\n",
    "    @staticmethod\n",
    "    def manhattan(node_1:Node, node_2:Node)->int:\n",
    "        \"\"\"\n",
    "        Compute manhattan distance between two nodes\n",
    "\n",
    "        node_1: first node to be computed --> Node\n",
    "        node_2: second node to be computed --> Node\n",
    "        \"\"\"\n",
    "        start_x, start_y = node_1.state\n",
    "        target_x, target_y = node_2.state\n",
    "        return abs(start_x-target_x) + abs(start_y-target_y)\n",
    "    \n",
    "    def solver(self):\n",
    "        \"\"\"\n",
    "        A* Search algorithm\n",
    "        \"\"\"\n",
    "        # When pusing node into heap and there exists equal distance values, \n",
    "        # then heap will arrange those nodes in order of entry time.\n",
    "        self.heap = []\n",
    "        self.entry_count = 1\n",
    "        h_score_s2t = A_search.manhattan(self.start_node, self.target_node) # h_score from start to target\n",
    "        heapq.heappush(self.heap, (h_score_s2t, self.entry_count, self.start_node))\n",
    "\n",
    "        while self.heap and not self.find:\n",
    "            time.sleep(DELAY)\n",
    "            # Extract_Min\n",
    "            _, _, node = heapq.heappop(self.heap)\n",
    "\n",
    "            # If find target node, set self.find == True\n",
    "            if node.state == self.target_node.state:\n",
    "                self.find = True\n",
    "\n",
    "            # Mark node as visited\n",
    "            self.board.visited.add(node)\n",
    "            self.board.draw_board(return_cells=False)\n",
    "\n",
    "            # if there is no outgoing edge, continue while loop\n",
    "            if not self.adj_list[node]:\n",
    "                continue\n",
    "\n",
    "            # if there exists outgoing edges, iteration through all edges\n",
    "            for neighbor in self.adj_list[node]:\n",
    "                if neighbor not in self.board.visited:\n",
    "                    self.relax(node, neighbor)\n",
    "\n",
    "            pygame.display.flip()\n",
    "\n",
    "class BFS(Search):\n",
    "    \"\"\"\n",
    "    Breathe First Search algorithm\n",
    "    \"\"\"\n",
    "    def __init__(self, board:Board):\n",
    "        self.board = board\n",
    "        self.find = False\n",
    "    \n",
    "    def initialize(self):\n",
    "        \"\"\"\n",
    "        Create following information for solver:\n",
    "        node_dict: key is coordinate of node; value is node\n",
    "        \"\"\"\n",
    "        self.node_dict = {}\n",
    "        for i in range(self.board.v_cells):\n",
    "            for j in range(self.board.h_cells):\n",
    "                if (i,j) in self.board.wall:\n",
    "                    continue\n",
    "\n",
    "                pos = (i,j)\n",
    "                node = Node(pos, None, None)\n",
    "                if pos == self.board.start:\n",
    "                    self.start_node = node\n",
    "                elif pos == self.board.target:\n",
    "                    self.target_node = node\n",
    "                \n",
    "                self.node_dict[pos] = node\n",
    "\n",
    "    def solver(self):\n",
    "        \"\"\"\n",
    "        BFS algorithm\n",
    "        \"\"\"\n",
    "        self.queue = Queue()\n",
    "        self.queue.add(self.start_node)\n",
    "        self.queue.frontier.add(self.start_node.state)\n",
    "\n",
    "        while not self.queue.empty() and not self.find:\n",
    "            \n",
    "            time.sleep(DELAY)\n",
    "            node = self.queue.remove()\n",
    "            self.board.visited.add(node)\n",
    "            self.board.draw_board(return_cells=False)\n",
    "\n",
    "            neighbors = self.board.neighbors(node.state)\n",
    "            for action, (row, col) in neighbors:\n",
    "                # if find target node, stop loop\n",
    "                if (row, col) == self.target_node.state:\n",
    "                    self.target_node.parent = node\n",
    "                    self.target_node.action = action\n",
    "                    self.find = True\n",
    "                    break\n",
    "                \n",
    "                # if node is not visited and not in frontier, add node to queue\n",
    "                if (row, col) not in self.queue.frontier and \\\n",
    "                   self.node_dict[(row, col)] not in self.board.visited:\n",
    "\n",
    "                    neighbor = self.node_dict[(row, col)]\n",
    "                    neighbor.parent = node\n",
    "                    neighbor.action = action\n",
    "                    self.queue.add(neighbor)\n",
    "                    self.queue.frontier.add((row, col))\n",
    "\n",
    "            pygame.display.flip()\n",
    "\n",
    "class Q_Learning(Search):\n",
    "    \"\"\"\n",
    "    Q-Learning Algorithm: Q(s,a) <-- Q(s,a) + alpha*((reward+best_future_reward) - Q(s,a))\n",
    "    \n",
    "    alpha: learning rate, within range 0.0~1.0\n",
    "    epsilon: parameter for epsilon-greedy algorithm, within 0.0~1.0.\n",
    "             if epsilon equals to 0.0, it'll be equivalent to \n",
    "             best greedy algorithm.\n",
    "    \"\"\"\n",
    "    def __init__(self, board:Board, alpha=0.5, epsilon=0.1):\n",
    "        self.board = board\n",
    "        self.find = False\n",
    "\n",
    "        if alpha < 0.0 or alpha > 1.0:\n",
    "            raise ValueError(\"Learning rate should be within 0.0 ~ 1.0\")\n",
    "        else:\n",
    "            self.alpha = alpha\n",
    "        if epsilon < 0.0 or epsilon > 1.0:\n",
    "            raise ValueError(\"Learning rate should be within 0.0 ~ 1.0\")\n",
    "        else:\n",
    "            self.epsilon = epsilon\n",
    "    \n",
    "    def initialize(self):\n",
    "        \"\"\"\n",
    "        Create following information for solver:\n",
    "        node_dict: key is coordinate of node; value is node\n",
    "        \"\"\"\n",
    "        self.node_dict = {}\n",
    "        for i in range(self.board.v_cells):\n",
    "            for j in range(self.board.h_cells):\n",
    "                # if (i,j) in self.board.wall:\n",
    "                #     continue\n",
    "                pos = (i,j)\n",
    "                node = Node(pos, None, None)\n",
    "                if pos == self.board.start:\n",
    "                    self.start_node = node\n",
    "                elif pos == self.board.target:\n",
    "                    self.target_node = node\n",
    "                \n",
    "                self.node_dict[pos] = node\n",
    "        \n",
    "        self.q_values = defaultdict(dict)\n",
    "        for pos in self.node_dict:\n",
    "            neighbors = self.board.neighbors(pos, wall_included=True)\n",
    "            for _, neighbor in neighbors:\n",
    "                self.q_values[pos][neighbor] = 0\n",
    "\n",
    "    def update_q_value(self, state:tuple, next_state:tuple, reward:int):\n",
    "        \"\"\"\n",
    "        update q_values based on formula below:\n",
    "        Q(s, a) = Q(s, a) + alpha * (current_reward + best_future_reward - Q(s,a))\n",
    "        \n",
    "        state: position of node -> tuple\n",
    "        next_state: next position node after move -> tuple\n",
    "        reward: current_reward -> int\n",
    "        \"\"\"\n",
    "        old_q = self.q_values[state][next_state]\n",
    "        new_est = reward + self.best_reward(next_state)\n",
    "        new_q = old_q + self.alpha*(new_est - old_q)\n",
    "        self.q_values[state][next_state] = new_q\n",
    "\n",
    "    def best_reward(self, state:tuple)->float:\n",
    "        \"\"\"\n",
    "        return best_future_reward from a state.\n",
    "\n",
    "        state: position of node -> tuple\n",
    "        \"\"\"\n",
    "        next_states = self.board.neighbors(state, wall_included=True)\n",
    "        best = 0\n",
    "        \n",
    "        for _, next_state in next_states:\n",
    "            best = max(best, self.q_values[state][next_state])\n",
    "\n",
    "        return best\n",
    "\n",
    "    def choose_action(self, state:tuple, available_actions:list, epsilon=True)->tuple:\n",
    "        \"\"\"\n",
    "        return best action from a state\n",
    "\n",
    "        state: position of node -> tuple\n",
    "        available_actions: a list of all possible move -> list\n",
    "        epsilon: if epsilon is True, epsilon greedy algorithm will be used.\n",
    "                 else it'll return action with highest q_value.\n",
    "        \"\"\"\n",
    "        t = int(time.time())\n",
    "        random.seed(t)\n",
    "\n",
    "        q_values = []\n",
    "        for action in available_actions:\n",
    "            q_value = self.q_values[state][action]\n",
    "            q_values.append((q_value, action))\n",
    "\n",
    "        q_values = sorted(q_values, key=lambda x:x[0], reverse=True)\n",
    "        if not epsilon:\n",
    "            return q_values[0][1]\n",
    "        \n",
    "        else:\n",
    "            best_q = q_values[0]\n",
    "            chosen = random.choices([best_q, q_values], weights=[1-self.epsilon, self.epsilon])\n",
    "            if chosen != best_q:\n",
    "                chosen = random.choice(q_values)\n",
    "            return chosen[1]\n",
    "\n",
    "    def solver(self, n):\n",
    "        \"\"\"\n",
    "        Train AI to find shortest path using Q_Learning and DFS, do not allow AI to go back.\n",
    "        \"\"\"\n",
    "        print('Training Start')\n",
    "        search = self.initialize()\n",
    "\n",
    "        self.board.draw_board(return_cells=False)\n",
    "        pygame.display.flip()\n",
    "\n",
    "        for i in range(n):\n",
    "            stop = False\n",
    "            last_state = None\n",
    "            cur_state = None\n",
    "            self.trail_path = [self.start_node.state]\n",
    "            self.board.visited.add(self.start_node)\n",
    "            while not stop and self.trail_path:\n",
    "                # get current_state from last element of trail_path\n",
    "                cur_state = self.trail_path[-1]\n",
    "\n",
    "                # get all possible next_states have not been visited\n",
    "                neighbors = self.board.neighbors(cur_state, wall_included=True)\n",
    "                available_actions = [\n",
    "                    neighbor \n",
    "                    for _, neighbor in neighbors\n",
    "                    if self.node_dict[neighbor] not in self.board.visited\n",
    "                ]\n",
    "\n",
    "                # if every possible next_state has been visited and not find target, \n",
    "                # update q_value with -100 reward for last_state -> cur_state\n",
    "                # and pop cur_state from trail_path. (It means the path is dead end)\n",
    "                if len(available_actions) == 0 and len(self.board.visited) >= 3:\n",
    "                    if self.trail_path[-1] == self.start_node.state:\n",
    "                        self.trail_path.pop()\n",
    "                    \n",
    "                    else:\n",
    "                        last_state = self.trail_path[-2]\n",
    "                        self.update_q_value(\n",
    "                            state=last_state,\n",
    "                            next_state=cur_state,\n",
    "                            reward=-100\n",
    "                        )\n",
    "                        self.trail_path.pop()\n",
    "                    continue\n",
    "\n",
    "                next_state = self.choose_action(cur_state, available_actions)\n",
    "                # if next_state is wall, add to visited and update q_value with -10 reward\n",
    "                if next_state in self.board.wall:\n",
    "                    self.board.visited.add(self.node_dict[next_state])\n",
    "\n",
    "                    self.update_q_value(\n",
    "                        state=cur_state,\n",
    "                        next_state=next_state,\n",
    "                        reward=-10\n",
    "                    )\n",
    "                    continue\n",
    "                    \n",
    "                # if find target_node, update q_value with 100 reward\n",
    "                elif next_state == self.target_node.state:\n",
    "                    self.node_dict[next_state].parent = self.node_dict[cur_state]\n",
    "\n",
    "                    self.update_q_value(\n",
    "                        state=cur_state,\n",
    "                        next_state=next_state,\n",
    "                        reward=100\n",
    "                    )\n",
    "                    stop=True\n",
    "                    self.find = True\n",
    "\n",
    "                # normal path adding, update q_value with 0 reward\n",
    "                else:\n",
    "                    self.board.visited.add(self.node_dict[next_state])\n",
    "                    self.trail_path.append(next_state)\n",
    "                    self.node_dict[next_state].parent = self.node_dict[cur_state]\n",
    "\n",
    "                    self.update_q_value(\n",
    "                        state=cur_state,\n",
    "                        next_state=next_state,\n",
    "                        reward=0\n",
    "                    )\n",
    "\n",
    "                # draw condition of training\n",
    "                cells = self.board.draw_board()   \n",
    "                colour = self.board.colours[\"purple\"]                     \n",
    "                for i, j in self.trail_path:\n",
    "                    if (i, j) == self.board.start:\n",
    "                        continue\n",
    "                    rect = cells[i][j]\n",
    "                    pygame.draw.rect(self.board.screen, colour, rect)\n",
    "                pygame.display.flip()\n",
    "                \n",
    "            if stop:\n",
    "                self.board.clear_visited()\n",
    "            \n",
    "            if not self.trail_path:\n",
    "                break\n",
    "\n",
    "        # reset board.visited and board.path to ensure not effect output function\n",
    "        self.board.clear_visited()\n",
    "        print('Finish Training')\n",
    "\n",
    "    def output(self):\n",
    "        \"\"\"\n",
    "        Solve shortest path after training\n",
    "        \"\"\"\n",
    "        # start from start node\n",
    "        node = self.start_node\n",
    "        visited = {node.state}\n",
    "        self.board.path.append(node.state)\n",
    "        # while node is not target, keep path adding\n",
    "        count = 0\n",
    "        while node != self.target_node:\n",
    "            time.sleep(DELAY)\n",
    "            self.board.draw_board(return_cells=False)\n",
    "\n",
    "            neighbors = self.board.neighbors(node.state)\n",
    "            available_actions = [\n",
    "                neighbor \n",
    "                for _, neighbor in neighbors\n",
    "                if neighbor not in visited\n",
    "            ]\n",
    "            best_action = self.choose_action(node.state, available_actions, epsilon=False)\n",
    "\n",
    "            # get next node and append to board.path\n",
    "            new_node = self.node_dict[best_action]    \n",
    "            new_node.parent = node\n",
    "            visited.add(new_node.state)\n",
    "            if new_node.state in self.board.path:\n",
    "                print(\"Train Fail\")\n",
    "                break\n",
    "\n",
    "            self.board.path.append(new_node.state)\n",
    "            node = new_node\n",
    "            count += 1\n",
    "            pygame.display.flip()\n",
    "        \n",
    "        if node == self.target_node:\n",
    "            print('Total Step is {}'.format(count+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
